apiVersion: batch/v1
kind: Job
metadata:
  name: neural-recommender-training-job
  namespace: neural-recommender
  labels:
    app: neural-recommender
    component: training
spec:
  parallelism: 1
  completions: 1
  backoffLimit: 3
  ttlSecondsAfterFinished: 86400  # 24 hours
  template:
    metadata:
      labels:
        app: neural-recommender
        component: training
    spec:
      restartPolicy: Never
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: trainer
        image: neural-recommender:latest
        command: ["python", "train.py"]
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        - name: SAMPLE_SIZE
          value: "150000"
        - name: EPOCHS
          value: "25"
        - name: BATCH_SIZE
          value: "512"
        - name: LEARNING_RATE
          value: "0.001"
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
            nvidia.com/gpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: "1"
        volumeMounts:
        - name: training-data
          mountPath: /app/data
        - name: mlruns-storage
          mountPath: /app/mlruns
        - name: model-output
          mountPath: /app/models
      volumes:
      - name: training-data
        persistentVolumeClaim:
          claimName: training-data-pvc
      - name: mlruns-storage
        persistentVolumeClaim:
          claimName: mlruns-pvc
      - name: model-output
        persistentVolumeClaim:
          claimName: model-output-pvc
      nodeSelector:
        accelerator: nvidia-tesla-v100
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: neural-recommender-retrain
  namespace: neural-recommender
  labels:
    app: neural-recommender
    component: scheduled-training
spec:
  schedule: "0 2 * * 0"  # Every Sunday at 2 AM
  jobTemplate:
    spec:
      parallelism: 1
      completions: 1
      backoffLimit: 2
      template:
        metadata:
          labels:
            app: neural-recommender
            component: scheduled-training
        spec:
          restartPolicy: Never
          containers:
          - name: retrain
            image: neural-recommender:latest
            command: ["python", "train.py"]
            env:
            - name: ENVIRONMENT
              value: "production"
            - name: MLFLOW_TRACKING_URI
              value: "http://mlflow-service:5000"
            - name: SCHEDULED_TRAINING
              value: "true"
            resources:
              requests:
                memory: "2Gi"
                cpu: "1000m"
              limits:
                memory: "4Gi"
                cpu: "2000m"
            volumeMounts:
            - name: mlruns-storage
              mountPath: /app/mlruns
          volumes:
          - name: mlruns-storage
            persistentVolumeClaim:
              claimName: mlruns-pvc
---
apiVersion: batch/v1
kind: Job
metadata:
  name: neural-recommender-model-validation
  namespace: neural-recommender
  labels:
    app: neural-recommender
    component: validation
spec:
  parallelism: 1
  completions: 1
  backoffLimit: 2
  template:
    metadata:
      labels:
        app: neural-recommender
        component: validation
    spec:
      restartPolicy: Never
      containers:
      - name: validator
        image: neural-recommender:latest
        command: ["python", "testing.py"]
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service:5000"
        - name: VALIDATION_MODE
          value: "full"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: mlruns-storage
          mountPath: /app/mlruns
        - name: test-results
          mountPath: /app/test-results
      volumes:
      - name: mlruns-storage
        persistentVolumeClaim:
          claimName: mlruns-pvc
      - name: test-results
        emptyDir: {}
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: neural-recommender-health-check
  namespace: neural-recommender
  labels:
    app: neural-recommender
    component: health-check
spec:
  schedule: "*/15 * * * *"  # Every 15 minutes
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: health-checker
            image: curlimages/curl:latest
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting health check..."
              
              # Check main application
              if curl -f http://neural-recommender-service/health; then
                echo "‚úÖ Main app is healthy"
              else
                echo "‚ùå Main app is unhealthy"
                exit 1
              fi
              
              # Check MLflow
              if curl -f http://mlflow-service:5000/health; then
                echo "‚úÖ MLflow is healthy"
              else
                echo "‚ùå MLflow is unhealthy"
                exit 1
              fi
              
              echo "‚úÖ All services are healthy"
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "100m"
---
apiVersion: batch/v1
kind: Job
metadata:
  name: neural-recommender-data-migration
  namespace: neural-recommender
  labels:
    app: neural-recommender
    component: data-migration
spec:
  parallelism: 1
  completions: 1
  backoffLimit: 1
  template:
    metadata:
      labels:
        app: neural-recommender
        component: data-migration
    spec:
      restartPolicy: Never
      initContainers:
      - name: data-validator
        image: neural-recommender:latest
        command:
        - python
        - -c
        - |
          import pandas as pd
          import os
          
          print("üîç Validating data migration...")
          
          # Check if source data exists
          if os.path.exists('/data/source/movies_ratings_cleaned.csv'):
              df = pd.read_csv('/data/source/movies_ratings_cleaned.csv')
              print(f"‚úÖ Source data found: {len(df):,} rows")
              
              # Basic validation
              if len(df) > 1000000:
                  print("‚úÖ Data size validation passed")
              else:
                  print("‚ùå Data size too small")
                  exit(1)
                  
              # Check columns
              required_columns = ['userId', 'movieId', 'rating']
              missing_columns = []
              for col in required_columns:
                  if col not in df.columns and not any(col.lower() in str(c).lower() for c in df.columns):
                      missing_columns.append(col)
              
              if missing_columns:
                  print(f"‚ùå Missing columns: {missing_columns}")
                  exit(1)
              else:
                  print("‚úÖ Column validation passed")
                  
              print("‚úÖ Data validation completed successfully")
          else:
              print("‚ùå Source data not found")
              exit(1)
        volumeMounts:
        - name: source-data
          mountPath: /data/source
      containers:
      - name: migrator
        image: neural-recommender:latest
        command:
        - /bin/sh
        - -c
        - |
          echo "üöÄ Starting data migration..."
          
          # Copy data to destination
          cp /data/source/movies_ratings_cleaned.csv /data/destination/
          
          # Verify copy
          if [ -f "/data/destination/movies_ratings_cleaned.csv" ]; then
            echo "‚úÖ Data migration completed successfully"
          else
            echo "‚ùå Data migration failed"
            exit 1
          fi
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        volumeMounts:
        - name: source-data
          mountPath: /data/source
          readOnly: true
        - name: destination-data
          mountPath: /data/destination
      volumes:
      - name: source-data
        persistentVolumeClaim:
          claimName: source-data-pvc
      - name: destination-data
        persistentVolumeClaim:
          claimName: training-data-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: training-data-pvc
  namespace: neural-recommender
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 20Gi
  storageClassName: fast-ssd
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: model-output-pvc
  namespace: neural-recommender
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 5Gi
  storageClassName: standard
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: source-data-pvc
  namespace: neural-recommender
spec:
  accessModes:
    - ReadOnlyMany
  resources:
    requests:
      storage: 50Gi
  storageClassName: standard